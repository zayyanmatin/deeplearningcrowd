{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we'll use\n",
    "\n",
    "import numpy as np\n",
    "import os, glob, csv\n",
    "\n",
    "import tensorflow as tf\n",
    "# # librosa is a widely-used audio processing library\n",
    "import librosa\n",
    "\n",
    "import sklearn\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "from torchaudio import transforms as t\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "# # for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zayyanmatin/Desktop/Masters/DLAM'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non project stuff',\n",
       " 'Pytorch_Audio_Classifier_Procedure_Raw-Copy1.ipynb',\n",
       " 'Pytorch_Audio_Classifier_Procedure-Testing.ipynb',\n",
       " 'Pytorch_Audio_Classifier_Procedure_Raw-Copy3.ipynb',\n",
       " 'Untitled1.ipynb',\n",
       " 'test1.rtf',\n",
       " 'Pytorch_Audio_Classifier_Procedure_Mel-Copy1.ipynb',\n",
       " '.DS_Store',\n",
       " 'bgBinary.csv',\n",
       " 'Pytorch_Audio_Classifier_Procedure_Raw-Copy2.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'bird_bg04.wav',\n",
       " 'bg_class.csv',\n",
       " 'bgBinary 2.numbers',\n",
       " 'other projects',\n",
       " 'bgBinary_Crowd.csv',\n",
       " 'Training_Validation_Maker.ipynb',\n",
       " 'bgBinary.numbers',\n",
       " 'env',\n",
       " 'WaveNet-master ',\n",
       " '.ipynb_checkpoints',\n",
       " 'tensorflow-wavenet-master',\n",
       " 'Isolated_urban_sound_database',\n",
       " 'Pytorch_Audio_Classifier_Procedure_Raw.ipynb',\n",
       " 'Pytorch_Audio_Classifier_Procedure_Mel.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "csvData = pd.read_csv('./bgBinary_Crowd.csv')\n",
    "print(len(csvData))\n",
    "print(csvData.iloc[80,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 130\n",
      "Test set size: 32\n"
     ]
    }
   ],
   "source": [
    "class UrbanSoundDataset(Dataset):\n",
    "#rapper for the UrbanSound8K dataset\n",
    "    # Argument List\n",
    "    #  path to the UrbanSound8K csv file\n",
    "    #  path to the UrbanSound8K audio files\n",
    "    #  list of folders to use in the dataset\n",
    "    \n",
    "    def __init__(self, csv_path, file_path, folderList):\n",
    "        csvData = pd.read_csv(csv_path)\n",
    "        #initialize lists to hold file names, labels, and folder numbers\n",
    "        self.file_names = []\n",
    "        self.labels = []\n",
    "        self.folders = []\n",
    "        #loop through the csv entries and only add entries from folders in the folder list\n",
    "        for i in range(0,len(csvData)):\n",
    "            if csvData.iloc[i, 3] in folderList:\n",
    "                self.file_names.append(csvData.iloc[i, 0])\n",
    "                self.labels.append(csvData.iloc[i, 2])\n",
    "                self.folders.append(csvData.iloc[i, 3])\n",
    "                \n",
    "        self.file_path = file_path\n",
    "        self.mixer = torch.mean #UrbanSound8K uses two channels, this will convert them to one\n",
    "        self.folderList = folderList\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #format the file path and load the file\n",
    "        path = self.file_path + \"fold\" + str(self.folders[index]) + \"/\" + self.file_names[index]\n",
    "        sound = torchaudio.load(path, out = None, normalization = True)\n",
    "        #load returns a tensor with the sound data and the sampling frequency (44.1kHz for UrbanSound8K)\n",
    "        soundData = torch.mean(sound[0], 0, keepdim=False, out=None)\n",
    "        soundData = soundData.unsqueeze_(-1)\n",
    "        #downsample the audio to ~8kHz\n",
    "        tempData = torch.zeros([160000, 1]) #tempData accounts for audio clips that are too short\n",
    "        if soundData.numel() < 160000:\n",
    "            tempData[:soundData.numel()] = soundData[:]\n",
    "        else:\n",
    "            tempData[:] = soundData[:160000]\n",
    "        \n",
    "        soundData = tempData\n",
    "        soundFormatted = torch.zeros([32000, 1])\n",
    "        soundFormatted[:32000] = soundData[::5] #take every fifth sample of soundData\n",
    "        soundFormatted = soundFormatted.permute(1, 0)\n",
    "        return soundFormatted, self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    \n",
    "csv_path = './bgBinary_Crowd.csv'\n",
    "file_path = './Isolated_urban_sound_database/'\n",
    "\n",
    "train_set = UrbanSoundDataset(csv_path, file_path, range(0,4))\n",
    "test_set = UrbanSoundDataset(csv_path, file_path, [4])\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"Test set size: \" + str(len(test_set)))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 32, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 32, shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.UrbanSoundDataset at 0x14bf616a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgPool): AvgPool1d(kernel_size=(30,), stride=(30,), padding=(0,))\n",
      "  (fc1): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(30) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x10 \n",
    "        loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "        gLoss = loss\n",
    "        \n",
    "    if loss <= 0.00010:\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/130 (0%)]\tLoss: 0.613367\n",
      "Train Epoch: 1 [64/130 (40%)]\tLoss: 0.872276\n",
      "Train Epoch: 1 [8/130 (80%)]\tLoss: 0.000950\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 2 [0/130 (0%)]\tLoss: 0.118095\n",
      "Train Epoch: 2 [64/130 (40%)]\tLoss: 0.370967\n",
      "Train Epoch: 2 [8/130 (80%)]\tLoss: 0.000188\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 3 [0/130 (0%)]\tLoss: 0.157373\n",
      "Train Epoch: 3 [64/130 (40%)]\tLoss: 0.357671\n",
      "Train Epoch: 3 [8/130 (80%)]\tLoss: 0.027621\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 4 [0/130 (0%)]\tLoss: 0.155964\n",
      "Train Epoch: 4 [64/130 (40%)]\tLoss: 0.239620\n",
      "Train Epoch: 4 [8/130 (80%)]\tLoss: 0.001803\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 5 [0/130 (0%)]\tLoss: 0.234977\n",
      "Train Epoch: 5 [64/130 (40%)]\tLoss: 0.322073\n",
      "Train Epoch: 5 [8/130 (80%)]\tLoss: 1.748919\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 6 [0/130 (0%)]\tLoss: 0.137097\n",
      "Train Epoch: 6 [64/130 (40%)]\tLoss: 0.657765\n",
      "Train Epoch: 6 [8/130 (80%)]\tLoss: 2.018602\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 7 [0/130 (0%)]\tLoss: 0.252506\n",
      "Train Epoch: 7 [64/130 (40%)]\tLoss: 0.248251\n",
      "Train Epoch: 7 [8/130 (80%)]\tLoss: 0.000326\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 8 [0/130 (0%)]\tLoss: 0.073270\n",
      "Train Epoch: 8 [64/130 (40%)]\tLoss: 0.207290\n",
      "Train Epoch: 8 [8/130 (80%)]\tLoss: 0.019401\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 9 [0/130 (0%)]\tLoss: 1.016831\n",
      "Train Epoch: 9 [64/130 (40%)]\tLoss: 0.242734\n",
      "Train Epoch: 9 [8/130 (80%)]\tLoss: 0.003529\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 10 [0/130 (0%)]\tLoss: 0.155321\n",
      "Train Epoch: 10 [64/130 (40%)]\tLoss: 0.230294\n",
      "Train Epoch: 10 [8/130 (80%)]\tLoss: 0.117348\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 11 [0/130 (0%)]\tLoss: 0.091376\n",
      "Train Epoch: 11 [64/130 (40%)]\tLoss: 0.210971\n",
      "Train Epoch: 11 [8/130 (80%)]\tLoss: 0.063140\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 12 [0/130 (0%)]\tLoss: 0.199880\n",
      "Train Epoch: 12 [64/130 (40%)]\tLoss: 0.268276\n",
      "Train Epoch: 12 [8/130 (80%)]\tLoss: 3.461625\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 13 [0/130 (0%)]\tLoss: 0.131807\n",
      "Train Epoch: 13 [64/130 (40%)]\tLoss: 0.268688\n",
      "Train Epoch: 13 [8/130 (80%)]\tLoss: 0.007758\n",
      "\n",
      "Test set: Accuracy: 25/32 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/130 (0%)]\tLoss: 0.242328\n",
      "Train Epoch: 14 [64/130 (40%)]\tLoss: 0.199095\n",
      "Train Epoch: 14 [8/130 (80%)]\tLoss: 0.000731\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 15 [0/130 (0%)]\tLoss: 0.254025\n",
      "Train Epoch: 15 [64/130 (40%)]\tLoss: 0.514717\n",
      "Train Epoch: 15 [8/130 (80%)]\tLoss: 0.003585\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n",
      "Train Epoch: 16 [0/130 (0%)]\tLoss: 0.275696\n",
      "Train Epoch: 16 [64/130 (40%)]\tLoss: 0.163962\n",
      "Train Epoch: 16 [8/130 (80%)]\tLoss: 0.001851\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 17 [0/130 (0%)]\tLoss: 0.036518\n",
      "Train Epoch: 17 [64/130 (40%)]\tLoss: 0.186827\n",
      "Train Epoch: 17 [8/130 (80%)]\tLoss: 0.003804\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 18 [0/130 (0%)]\tLoss: 0.079817\n",
      "Train Epoch: 18 [64/130 (40%)]\tLoss: 0.200004\n",
      "Train Epoch: 18 [8/130 (80%)]\tLoss: 0.000036\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 19 [0/130 (0%)]\tLoss: 0.226521\n",
      "Train Epoch: 19 [64/130 (40%)]\tLoss: 0.167780\n",
      "Train Epoch: 19 [8/130 (80%)]\tLoss: 0.000025\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 20 [0/130 (0%)]\tLoss: 0.186542\n",
      "Train Epoch: 20 [64/130 (40%)]\tLoss: 0.130923\n",
      "Train Epoch: 20 [8/130 (80%)]\tLoss: 0.039404\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 21 [0/130 (0%)]\tLoss: 0.038992\n",
      "Train Epoch: 21 [64/130 (40%)]\tLoss: 0.154573\n",
      "Train Epoch: 21 [8/130 (80%)]\tLoss: 0.083735\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 22 [0/130 (0%)]\tLoss: 0.022997\n",
      "Train Epoch: 22 [64/130 (40%)]\tLoss: 0.104643\n",
      "Train Epoch: 22 [8/130 (80%)]\tLoss: 0.009756\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 23 [0/130 (0%)]\tLoss: 0.088695\n",
      "Train Epoch: 23 [64/130 (40%)]\tLoss: 0.127069\n",
      "Train Epoch: 23 [8/130 (80%)]\tLoss: 0.000225\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 24 [0/130 (0%)]\tLoss: 0.108267\n",
      "Train Epoch: 24 [64/130 (40%)]\tLoss: 0.044178\n",
      "Train Epoch: 24 [8/130 (80%)]\tLoss: 0.000008\n",
      "\n",
      "Test set: Accuracy: 28/32 (88%)\n",
      "\n",
      "Train Epoch: 25 [0/130 (0%)]\tLoss: 0.063251\n",
      "Train Epoch: 25 [64/130 (40%)]\tLoss: 0.032080\n",
      "Train Epoch: 25 [8/130 (80%)]\tLoss: 4.020816\n",
      "\n",
      "Test set: Accuracy: 26/32 (81%)\n",
      "\n",
      "Train Epoch: 26 [0/130 (0%)]\tLoss: 0.116007\n",
      "Train Epoch: 26 [64/130 (40%)]\tLoss: 0.107199\n",
      "Train Epoch: 26 [8/130 (80%)]\tLoss: 0.001028\n",
      "\n",
      "Test set: Accuracy: 27/32 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_interval = 2\n",
    "for epoch in range(1, 27):\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "    \n",
    "    train(model, epoch)\n",
    "    test(model, epoch)\n",
    "#     if train(model, epoch) == 1:\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'raw.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
